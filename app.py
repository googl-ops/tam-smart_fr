#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ù…Ù†ØµØ© ØªØ§Ù… Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ© - Ø§Ù„ÙØ±Ø§Ù‡ÙŠØ¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
TAM Smart Cultural Platform - Advanced Al-Farahidi
"""

import subprocess
import sys

def install_packages():
    packages = ['streamlit', 'requests', 'pandas', 'numpy', 'plotly']
    for package in packages:
        try:
            __import__(package)
        except ImportError:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])

install_packages()

import streamlit as st
import pandas as pd
import numpy as np
import requests
import re
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Set
from enum import Enum

st.set_page_config(
    page_title="Ù…Ø®ØªØ¨Ø± Ø§Ù„ÙØ±Ø§Ù‡ÙŠØ¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ | Ù…Ù†ØµØ© ØªØ§Ù…",
    page_icon="ğ©©",
    layout="wide",
    initial_sidebar_state="collapsed"
)

COLORS = {
    'midnight_blue': '#071A2F',
    'aged_gold': '#C8A44D',
    'electric_turquoise': '#00d4c8',
    'electric_turquoise_glow': 'rgba(0, 212, 200, 0.5)',
    'sandstone_cream': '#f5f0e3',
    'error_red': '#ff4757',
    'warning_orange': '#ffa502',
    'success_green': '#2ed573',
    'purple': '#9b59b6',
    'cyan': '#00cec9',
    'gradient_gold': 'linear-gradient(180deg, #d4af37 0%, #C8A44D 50%, #b8941f 100%)',
    'silver_gradient': 'linear-gradient(145deg, #E8E8E8 0%, #C0C0C0 30%, #A0A0A0 60%, #D0D0D0 100%)'
}

st.markdown(f"""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Naskh+Arabic:wght@400;500;700&family=Cairo:wght@300;400;600;800&family=Noto+Kufi+Arabic:wght@400;700&family=Montserrat:wght@400;700&display=swap');
    
    .stApp {{
        background: {COLORS['midnight_blue']};
        font-family: 'Cairo', 'Noto Naskh Arabic', sans-serif;
        color: {COLORS['sandstone_cream']};
    }}
    
    header {{ background: rgba(7, 26, 47, 0.95) !important; border-bottom: 1px solid {COLORS['aged_gold']}40; }}
    #MainMenu {{visibility: hidden;}}
    footer {{visibility: hidden;}}
    .stDeployButton {{display:none;}}
    
    .main .block-container {{
        max-width: 1000px; padding: 2rem;
        background: rgba(7, 26, 47, 0.6);
        border: 1px solid {COLORS['aged_gold']}40;
        border-radius: 30px;
        margin-top: 2rem;
    }}
    
    .tam-logo-container {{
        display: flex; flex-direction: column; align-items: center;
        gap: 5px; margin-bottom: 2rem; text-align: center;
    }}
    
    .tam-musnad {{
        font-family: 'Times New Roman', serif; font-size: 4rem; font-weight: bold;
        background: linear-gradient(145deg, #FFF5C3, #C8A44D 40%, #FFD700);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        line-height: 1;
    }}
    
    .tam-english {{
        font-family: 'Montserrat', sans-serif; font-size: 2rem; font-weight: 700;
        letter-spacing: 0.2em; text-transform: uppercase;
        background: {COLORS['silver_gradient']};
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        line-height: 1;
    }}
    
    .tam-arabic {{
        font-family: 'Noto Kufi Arabic', sans-serif; font-size: 3.5rem; font-weight: bold;
        color: {COLORS['aged_gold']};
        text-shadow: 5px 5px 10px rgba(0,0,0,0.9);
        line-height: 1;
    }}
    
    .tam-separator {{
        height: 4px; width: 80%; margin: 10px auto;
        background: linear-gradient(to right, transparent, {COLORS['aged_gold']}, transparent);
    }}
    
    .tam-platform-name {{
        font-family: 'Noto Kufi Arabic', sans-serif; font-size: 1.5rem; font-weight: 700;
        color: {COLORS['aged_gold']};
        text-shadow: 4px 4px 8px rgba(0,0,0,0.9);
        margin-top: 0.5rem;
    }}
    
    .farahidi-title {{
        margin-top: 2rem; padding: 0.5rem 2rem;
        border: 1px solid {COLORS['electric_turquoise']}; border-radius: 50px;
        color: {COLORS['electric_turquoise']}; font-family: 'Noto Kufi Arabic', sans-serif;
        font-size: 1.2rem; background: rgba(0, 212, 200, 0.1);
        display: inline-flex; align-items: center; gap: 0.5rem;
    }}
    
    .stTextArea textarea {{
        background: rgba(255, 255, 255, 0.03) !important;
        border: 2px solid {COLORS['aged_gold']}60 !important;
        border-radius: 15px !important;
        color: {COLORS['sandstone_cream']} !important;
        font-family: 'Noto Naskh Arabic', serif !important;
        font-size: 1.2rem !important;
        line-height: 2 !important;
        text-align: center !important;
        direction: rtl !important;
        min-height: 150px !important;
        padding: 20px !important;
    }}
    
    .stTextArea textarea:focus {{
        border-color: {COLORS['electric_turquoise']} !important;
        box-shadow: 0 0 15px {COLORS['electric_turquoise_glow']} !important;
        background: rgba(10, 25, 50, 0.95) !important;
    }}
    
    .stTextArea textarea::placeholder {{
        color: rgba(245, 240, 227, 0.5) !important;
        font-size: 1.2rem !important;
    }}
    
    .stTextArea label {{ display: none !important; }}
    .stTextArea > div > div {{ background: transparent !important; }}
    
    .stButton > button {{
        font-family: 'Noto Kufi Arabic', sans-serif !important; font-weight: 700 !important;
        font-size: 1.1rem !important; border-radius: 50px !important;
        padding: 1rem 2.5rem !important; border: none !important;
        cursor: pointer !important;
    }}
    
    .btn-gold > button {{
        background: linear-gradient(180deg, #d4af37 0%, #C8A44D 50%, #b8941f 100%) !important;
        color: {COLORS['midnight_blue']} !important;
    }}
    
    .btn-outline > button {{
        background: transparent !important; border: 2px solid {COLORS['electric_turquoise']} !important;
        color: {COLORS['electric_turquoise']} !important;
    }}
    
    .btn-danger > button {{
        background: transparent !important; border: 2px solid #ff6b6b !important;
        color: #ff6b6b !important;
    }}
    
    .tafeela-card {{
        background: rgba(10, 22, 40, 0.8);
        border-radius: 15px; padding: 1.5rem; margin: 1rem 0;
        border: 2px solid {COLORS['aged_gold']}40;
        text-align: center; position: relative;
    }}
    
    .tafeela-card.error {{ border-color: {COLORS['error_red']}; }}
    .tafeela-card.warning {{ border-color: {COLORS['warning_orange']}; }}
    .tafeela-card.success {{ border-color: {COLORS['success_green']}; }}
    .tafeela-card.purple {{ border-color: {COLORS['purple']}; }}
    .tafeela-card.cyan {{ border-color: {COLORS['cyan']}; }}
    
    .tafeela-name {{
        font-family: 'Noto Kufi Arabic', sans-serif;
        font-size: 1.8rem; font-weight: bold;
        color: {COLORS['electric_turquoise']}; margin-bottom: 0.5rem;
    }}
    
    .tafeela-pattern {{
        font-family: 'Courier New', monospace; font-size: 1.3rem;
        color: {COLORS['sandstone_cream']}; letter-spacing: 0.2em;
        direction: ltr; display: inline-block;
    }}
    
    .status-message {{
        padding: 1.5rem; border-radius: 15px; margin: 1rem 0;
        font-family: 'Noto Kufi Arabic', sans-serif; text-align: center;
    }}
    
    .status-message.success {{
        background: rgba(46, 213, 115, 0.2);
        border: 2px solid {COLORS['success_green']};
        color: {COLORS['success_green']};
    }}
    
    .status-message.warning {{
        background: rgba(255, 165, 2, 0.2);
        border: 2px solid {COLORS['warning_orange']};
        color: {COLORS['warning_orange']};
    }}
    
    .status-message.error {{
        background: rgba(255, 71, 87, 0.2);
        border: 2px solid {COLORS['error_red']};
        color: {COLORS['error_red']};
    }}
    
    .result-card {{
        background: rgba(10, 22, 40, 0.6);
        border-right: 4px solid {COLORS['electric_turquoise']};
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        display: flex;
        align-items: center;
        justify-content: space-between;
    }}
    
    .result-label {{
        color: {COLORS['aged_gold']};
        font-weight: bold;
        font-size: 0.9rem;
    }}
    
    .result-value {{
        font-size: 1.4rem;
        color: {COLORS['sandstone_cream']};
    }}
    
    .technical-box {{
        background: rgba(0, 0, 0, 0.3);
        border-radius: 10px; padding: 1rem;
        font-family: 'Courier New', monospace;
        direction: ltr; text-align: left;
        font-size: 1.1rem; color: {COLORS['electric_turquoise']};
        word-break: break-all;
    }}
    
    .diacritics-box {{
        background: rgba(0, 0, 0, 0.2);
        border: 1px dashed {COLORS['electric_turquoise']};
        padding: 20px;
        border-radius: 10px;
        font-family: 'Noto Naskh Arabic';
        font-size: 1.3rem;
        line-height: 2.5;
        text-align: center;
        color: #fff;
        margin-top: 20px;
    }}
    
    .qafiya-box {{
        background: rgba(155, 89, 182, 0.2);
        border: 2px solid {COLORS['purple']};
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        text-align: center;
    }}
    
    .meter-type-badge {{
        display: inline-block;
        padding: 0.5rem 1.5rem;
        border-radius: 25px;
        font-weight: bold;
        font-family: 'Noto Kufi Arabic';
        margin: 0.5rem;
    }}
    
    .badge-tam {{ background: {COLORS['success_green']}; color: white; }}
    .badge-majzoo {{ background: {COLORS['warning_orange']}; color: white; }}
    .badge-mashtoor {{ background: {COLORS['purple']}; color: white; }}
    .badge-manhooq {{ background: {COLORS['error_red']}; color: white; }}
    .badge-mutafa {{ background: {COLORS['cyan']}; color: white; }}
    
    .tam-footer {{
        text-align: center; padding: 2rem;
        color: rgba(245, 240, 227, 0.5); font-size: 0.9rem;
        margin-top: 2rem; border-top: 1px solid {COLORS['aged_gold']}20;
    }}
    
    .stTabs [data-baseweb="tab-list"] {{
        gap: 20px;
        background-color: rgba(10, 22, 40, 0.5);
        padding: 10px;
        border-radius: 15px;
        border: 1px solid {COLORS['aged_gold']}40;
    }}
    
    .stTabs [data-baseweb="tab"] {{
        height: 50px;
        white-space: pre-wrap;
        background-color: transparent;
        border-radius: 10px;
        color: {COLORS['sandstone_cream']};
        font-family: 'Noto Kufi Arabic';
    }}
    
    .stTabs [aria-selected="true"] {{
        background-color: {COLORS['electric_turquoise']} !important;
        color: {COLORS['midnight_blue']} !important;
        font-weight: bold;
    }}
    
    .stMarkdown, .stTextArea, div[data-testid="stVerticalBlock"] {{
        background: transparent !important;
    }}
    
    div[data-testid="stVerticalBlock"] > div {{
        background: transparent !important;
    }}
    
    .element-container {{
        background: transparent !important;
    }}
    
    .stExpander {{
        background: rgba(10, 22, 40, 0.6) !important;
        border-radius: 15px;
        border: 1px solid {COLORS['aged_gold']}40;
    }}
</style>
""", unsafe_allow_html=True)

class MeterType(Enum):
    TAM = "ØªØ§Ù…"
    MAJZOO = "Ù…Ø¬Ø²ÙˆØ¡"
    MASHTOOR = "Ù…Ø´Ø·ÙˆØ±"
    MANHOOQ = "Ù…Ù†Ù‡ÙˆÙƒ"
    MUTAFAILA = "Ù…ØªÙØ§Ø¹Ù„Ø©"

class QafiyaType(Enum):
    ISNAD = "Ø¥Ø³Ù†Ø§Ø¯"
    TARKEEB = "ØªØ±ÙƒÙŠØ¨"
    TAM = "ØªÙ…"
    MURABA = "Ù…Ø±ØªØ§Ø¨Ø¹"
    MUTLAQ = "Ù…Ø·Ù„Ù‚"
    MUTADARIK = "Ù…ØªØ¯Ø§Ø±Ùƒ"
    MUKARRAM = "Ù…ÙƒØ±Ø±"
    MUTAWAZI = "Ù…ØªÙˆØ§Ø²Ù"
    MUTAMAN = "Ù…ØªÙ…Ø§Ø«Ù„"
    MUTAJANIS = "Ù…ØªØ¬Ø§Ù†Ø³"

@dataclass
class TafeelaResult:
    name: str
    pattern: str
    actual: str
    status: str
    position: int
    zahaf: Optional[str] = None
    is_complete: bool = True

@dataclass
class QafiyaAnalysis:
    rawwiy: str
    type: QafiyaType
    pattern: str
    is_valid: bool
    details: str

@dataclass
class ShatrAnalysis:
    original_text: str = ""
    arudi_text: str = ""
    binary_code: str = ""
    tafeelat: List[TafeelaResult] = field(default_factory=list)
    meter_name: Optional[str] = None
    meter_type: MeterType = None
    meter_subtype: str = ""
    confidence: float = 0.0
    is_valid: bool = False
    qafiya: Optional[QafiyaAnalysis] = None
    is_single_tafeela: bool = False

class DiacriticsEngine:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØ§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù„ØºÙˆÙŠ"""
    
    @staticmethod
    def add_diacritics(text: str) -> str:
        try:
            url = "https://qutrub.arabeyes.org/api/diacritize"
            response = requests.post(url, json={"text": text}, timeout=5)
            if response.status_code == 200:
                return response.json().get("diacritized_text", text)
        except:
            pass
        return DiacriticsEngine._fallback_diacritics(text)
    
    @staticmethod
    def _fallback_diacritics(text: str) -> str:
        lines = text.strip().split('\n')
        diacritized_lines = []
        
        for line in lines:
            words = line.split()
            diacritized_words = []
            
            for word in words:
                diacritized_word = DiacriticsEngine._apply_basic_diacritics(word)
                diacritized_words.append(diacritized_word)
            
            diacritized_lines.append(' '.join(diacritized_words))
        
        return '\n'.join(diacritized_lines)
    
    @staticmethod
    def _apply_basic_diacritics(word: str) -> str:
        if not word:
            return word
        
        if word.endswith('Øª') or word.endswith('Ù†') or word.endswith('Ø§'):
            if not any(h in word for h in 'ÙÙÙÙ’Ù‘Ù‹ÙŒÙ'):
                return word + 'Ù'
        
        if len(word) <= 3:
            return word + 'Ù'
        
        return word

class ArabicTextEngine:
    """Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠ Ø§Ù„Ø°ÙƒÙŠ"""
    
    ARABIC_LETTERS = set('Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠÙ‰')
    HARAKAT = set('ÙÙÙÙ’Ù‘Ù‹ÙŒÙ')
    SOLAR_LETTERS = set('ØªØ«Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ù„Ù†')

    @classmethod
    def normalize_text(cls, text: str) -> str:
        if not text: 
            return ""
        text = text.replace('\u0640', '')
        hamza_map = {'Ø£': 'Ø§', 'Ø¥': 'Ø§', 'Ø¢': 'Ø§', 'Ù±': 'Ø§', 'Ø¤': 'Ùˆ', 'Ø¦': 'ÙŠ', 'Ø¡': ''}
        for old, new in hamza_map.items():
            text = text.replace(old, new)
        text = text.replace('Ø©', 'Ù‡')
        allowed = cls.ARABIC_LETTERS | cls.HARAKAT | {' ', '\n'}
        return ''.join(c for c in text if c in allowed)

    @classmethod
    def _infer_vowel(cls, char: str, position: int, text: str, previous_tokens: List[Dict]) -> Dict:
        if position == len(text) - 1 or (position + 1 < len(text) and text[position + 1] == ' '):
            if char in 'Ø¯Ø°Ø±Ø²Ø³ÙˆÙŠ':
                return {'type': 'sakin', 'symbol': 'Ù’', 'source': 'rule_waqf'}
        
        if char == 'ÙŠ': 
            return {'type': 'mutaharrik', 'symbol': 'Ù', 'source': 'rule_ya'}
        elif char == 'Ùˆ': 
            return {'type': 'mutaharrik', 'symbol': 'Ù', 'source': 'rule_waw'}
        elif char == 'Ø§': 
            return {'type': 'sakin', 'symbol': 'Ù’', 'source': 'rule_alif'}
        
        return {'type': 'mutaharrik', 'symbol': 'Ù', 'source': 'default'}

    @classmethod
    def smart_tokenize(cls, text: str) -> List[Dict]:
        text = cls.normalize_text(text)
        tokens = []
        i = 0
        length = len(text)
        
        while i < length:
            char = text[i]
            if char == ' ' or char == '\n':
                i += 1
                continue
            if char not in cls.ARABIC_LETTERS:
                i += 1
                continue
            
            next_char = text[i+1] if i+1 < length else None
            
            if char == 'Ø§' and next_char == 'Ù„':
                after_lam = text[i+2] if i+2 < length else None
                if after_lam and after_lam in cls.SOLAR_LETTERS:
                    tokens.append({'letter': 'Ø§', 'haraka': {'type': 'mutaharrik', 'symbol': 'Ù'}})
                    i += 2
                    continue
                else:
                    tokens.append({'letter': 'Ø§', 'haraka': {'type': 'mutaharrik', 'symbol': 'Ù'}})
                    tokens.append({'letter': 'Ù„', 'haraka': {'type': 'sakin', 'symbol': 'Ù’'}})
                    i += 2
                    continue

            if next_char in cls.HARAKAT:
                if next_char == 'Ù‘':
                    tokens.append({'letter': char, 'haraka': {'type': 'sakin', 'symbol': 'Ù’'}})
                    tokens.append({'letter': char, 'haraka': {'type': 'mutaharrik', 'symbol': 'Ù'}})
                    i += 2
                elif next_char == 'Ù’':
                    tokens.append({'letter': char, 'haraka': {'type': 'sakin', 'symbol': 'Ù’'}})
                    i += 2
                else:
                    tokens.append({'letter': char, 'haraka': {'type': 'mutaharrik', 'symbol': next_char}})
                    i += 2
                continue

            haraka = cls._infer_vowel(char, i, text, tokens)
            tokens.append({'letter': char, 'haraka': haraka})
            i += 1
            
        return tokens

    @classmethod
    def tokens_to_binary(cls, tokens: List[Dict]) -> str:
        return ''.join('1' if t['haraka']['type'] == 'mutaharrik' else '0' for t in tokens)

    @classmethod
    def tokens_to_arudi(cls, tokens: List[Dict]) -> str:
        return ' '.join(f"{t['letter']}{'Ù…' if t['haraka']['type'] == 'mutaharrik' else 'Ø³'}" for t in tokens)

class MetersDatabase:
    """Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ø­ÙˆØ± Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
    
    TAFEELAT = {
        'ÙØ¹ÙˆÙ„Ù†': '11010',
        'Ù…ÙØ§Ø¹ÙŠÙ„Ù†': '1101010',
        'Ù…ÙØ§Ø¹Ù„Ù†': '110110',
        'ÙØ§Ø¹Ù„Ø§ØªÙ†': '1011010',
        'ÙØ§Ø¹Ù„Ù†': '10110',
        'Ù…Ø³ØªÙØ¹Ù„Ù†': '1011010',
        'Ù…ØªÙØ§Ø¹Ù„Ù†': '1110110',
        'Ù…ÙØ§Ø¹Ù„ØªÙ†': '1101110',
        'ÙÙØ¹ÙÙˆÙ„ÙÙ†': '11010',
        'Ù…ÙÙÙØ§Ø¹ÙÙŠÙ„ÙÙ†': '1101010',
        'Ù…ÙÙÙØ§Ø¹ÙÙ„ÙÙ†': '110110',
        'ÙÙØ§Ø¹ÙÙ„ÙØ§ØªÙÙ†': '1011010',
        'ÙÙØ§Ø¹ÙÙ„ÙÙ†': '10110',
        'Ù…ÙØ³Ù’ØªÙÙÙ’Ø¹ÙÙ„ÙÙ†': '1011010',
        'Ù…ÙØªÙÙÙØ§Ø¹ÙÙ„ÙÙ†': '1110110',
        'Ù…ÙÙÙØ§Ø¹ÙÙ„ÙØªÙÙ†': '1101110'
    }
    
    # Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨Ø­ÙˆØ±: ØªØ§Ù…ØŒ Ù…Ø¬Ø²ÙˆØ¡ØŒ Ù…Ø´Ø·ÙˆØ±ØŒ Ù…Ù†Ù‡ÙˆÙƒØŒ Ù…ØªÙØ§Ø¹Ù„Ø©
    METERS = {
        'Ø§Ù„Ø·ÙˆÙŠÙ„': {
            'ØªØ§Ù…': ['ÙØ¹ÙˆÙ„Ù†', 'Ù…ÙØ§Ø¹ÙŠÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†', 'Ù…ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['ÙØ¹ÙˆÙ„Ù†', 'Ù…ÙØ§Ø¹ÙŠÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ¹ÙˆÙ„Ù†', 'Ù…ÙØ§Ø¹ÙŠÙ„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ¹ÙˆÙ„Ù†'],
            'Ù…ØªÙØ§Ø¹Ù„Ø©': ['ÙØ¹ÙˆÙ„Ù†']
        },
        'Ø§Ù„Ù…Ø¯ÙŠØ¯': {
            'ØªØ§Ù…': ['ÙØ§Ø¹Ù„Ø§ØªÙ†', 'ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['ÙØ§Ø¹Ù„Ø§ØªÙ†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ§Ø¹Ù„Ù†']
        },
        'Ø§Ù„Ø¨Ø³ÙŠØ·': {
            'ØªØ§Ù…': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['Ù…Ø³ØªÙØ¹Ù„Ù†']
        },
        'Ø§Ù„ÙˆØ§ÙØ±': {
            'ØªØ§Ù…': ['Ù…ÙØ§Ø¹Ù„ØªÙ†', 'Ù…ÙØ§Ø¹Ù„ØªÙ†', 'ÙØ¹ÙˆÙ„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…ÙØ§Ø¹Ù„ØªÙ†', 'Ù…ÙØ§Ø¹Ù„ØªÙ†'],
            'Ù…Ø´Ø·ÙˆØ±': ['Ù…ÙØ§Ø¹Ù„ØªÙ†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ¹ÙˆÙ„Ù†']
        },
        'Ø§Ù„ÙƒØ§Ù…Ù„': {
            'ØªØ§Ù…': ['Ù…ØªÙØ§Ø¹Ù„Ù†', 'Ù…ØªÙØ§Ø¹Ù„Ù†', 'Ù…ØªÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…ØªÙØ§Ø¹Ù„Ù†', 'Ù…ØªÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['Ù…ØªÙØ§Ø¹Ù„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['Ù…ØªÙØ§Ø¹Ù„Ù†']
        },
        'Ø§Ù„Ù‡Ø²Ø¬': {
            'ØªØ§Ù…': ['Ù…ÙØ§Ø¹ÙŠÙ„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…ÙØ§Ø¹ÙŠÙ„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['Ù…ÙØ§Ø¹ÙŠÙ„Ù†']
        },
        'Ø§Ù„Ø±Ø¬Ø²': {
            'ØªØ§Ù…': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['Ù…Ø³ØªÙØ¹Ù„Ù†']
        },
        'Ø§Ù„Ø±Ù…Ù„': {
            'ØªØ§Ù…': ['ÙØ§Ø¹Ù„Ø§ØªÙ†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['ÙØ§Ø¹Ù„Ø§ØªÙ†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ§Ø¹Ù„Ø§ØªÙ†']
        },
        'Ø§Ù„Ø³Ø±ÙŠØ¹': {
            'ØªØ§Ù…': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ§Ø¹Ù„Ù†']
        },
        'Ø§Ù„Ù…Ù†Ø³Ø±Ø­': {
            'ØªØ§Ù…': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†', 'Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†', 'Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['Ù…Ø³ØªÙØ¹Ù„Ù†']
        },
        'Ø§Ù„Ø®ÙÙŠÙ': {
            'ØªØ§Ù…': ['ÙØ§Ø¹Ù„Ø§ØªÙ†', 'Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['ÙØ§Ø¹Ù„Ø§ØªÙ†', 'Ù…Ø³ØªÙØ¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ§Ø¹Ù„Ø§ØªÙ†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['Ù…Ø³ØªÙØ¹Ù„Ù†']
        },
        'Ø§Ù„Ù…ØªÙ‚Ø§Ø±Ø¨': {
            'ØªØ§Ù…': ['ÙØ¹ÙˆÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['ÙØ¹ÙˆÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ¹ÙˆÙ„Ù†', 'ÙØ¹ÙˆÙ„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ¹ÙˆÙ„Ù†']
        },
        'Ø§Ù„Ù…ØªØ¯Ø§Ø±Ùƒ': {
            'ØªØ§Ù…': ['ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø¬Ø²ÙˆØ¡': ['ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ø´Ø·ÙˆØ±': ['ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ù†'],
            'Ù…Ù†Ù‡ÙˆÙƒ': ['ÙØ§Ø¹Ù„Ù†']
        }
    }

class QafiyaAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù‚ÙˆØ§ÙÙŠ"""
    
    HARAKAT_END = {'Ù': 'ÙØªØ­Ø©', 'Ù': 'Ø¶Ù…Ø©', 'Ù': 'ÙƒØ³Ø±Ø©', 'Ù‹': 'ØªÙ†ÙˆÙŠÙ† ÙØªØ­', 'ÙŒ': 'ØªÙ†ÙˆÙŠÙ† Ø¶Ù…', 'Ù': 'ØªÙ†ÙˆÙŠÙ† ÙƒØ³Ø±'}
    
    @staticmethod
    def extract_rawwiy(text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆÙŠ Ù…Ù† Ø¢Ø®Ø± ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØª"""
        words = text.strip().split()
        if not words:
            return ""
        last_word = words[-1]
        
        # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…
        last_word = re.sub(r'[^\w\s]', '', last_word)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø£Ø®ÙŠØ± Ø§Ù„Ù…ØªØ­Ø±Ùƒ
        for char in reversed(last_word):
            if char in QafiyaAnalyzer.HARAKAT_END:
                return char
            elif char in 'Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠÙ‰':
                return char + 'Ù’'
        
        return last_word[-1] if last_word else ""
    
    @staticmethod
    def analyze_qafiya(text: str, previous_lines: List[str] = None) -> QafiyaAnalysis:
        """ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø§ÙÙŠØ©"""
        rawwiy = QafiyaAnalyzer.extract_rawwiy(text)
        
        if not rawwiy:
            return QafiyaAnalysis("", QafiyaType.MUTLAQ, "", False, "Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆÙŠ")
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø§ÙÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆÙŠ
        if 'Ù‹' in rawwiy or 'ÙŒ' in rawwiy or 'Ù' in rawwiy:
            qafiya_type = QafiyaType.TARKEEB
            pattern = "ØªÙ†ÙˆÙŠÙ†"
        elif rawwiy.endswith('Ù'):
            qafiya_type = QafiyaType.ISNAD
            pattern = "ÙØªØ­Ø©"
        elif rawwiy.endswith('Ù'):
            qafiya_type = QafiyaType.MURABA
            pattern = "Ø¶Ù…Ø©"
        elif rawwiy.endswith('Ù'):
            qafiya_type = QafiyaType.MUTADARIK
            pattern = "ÙƒØ³Ø±Ø©"
        elif rawwiy.endswith('Ù’'):
            qafiya_type = QafiyaType.MUTLAQ
            pattern = "Ø³ÙƒÙˆÙ†"
        else:
            qafiya_type = QafiyaType.MUTLAQ
            pattern = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù‚Ø§ÙÙŠØ© Ù…Ø¹ Ø§Ù„Ø£Ø¨ÙŠØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        is_valid = True
        details = f"Ø§Ù„Ø±ÙˆÙŠ: {rawwiy} ({pattern})"
        
        if previous_lines:
            prev_rawwiyat = [QafiyaAnalyzer.extract_rawwiy(line) for line in previous_lines if line.strip()]
            if prev_rawwiyat and rawwiy != prev_rawwiyat[-1]:
                is_valid = False
                details += " - âš ï¸ Ø§Ù„Ø±ÙˆÙŠ Ù„Ø§ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø³Ø§Ø¨Ù‚"
            else:
                details += " - âœ… Ø§Ù„Ø±ÙˆÙŠ Ù…ØªØ·Ø§Ø¨Ù‚"
        
        return QafiyaAnalysis(rawwiy, qafiya_type, pattern, is_valid, details)

class FarahidiAnalyzer:
    """Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.engine = ArabicTextEngine()
        self.db = MetersDatabase()
        self.qafiya_analyzer = QafiyaAnalyzer()
    
    def analyze(self, text: str, previous_lines: List[str] = None) -> ShatrAnalysis:
        tokens = self.engine.smart_tokenize(text)
        if not tokens: 
            return ShatrAnalysis()
        
        binary = self.engine.tokens_to_binary(tokens)
        arudi = self.engine.tokens_to_arudi(tokens)
        tafeelat = self._extract_tafeelat(binary)
        meter_match = self._match_meter(tafeelat)
        confidence = self._calculate_confidence(tafeelat, meter_match, binary)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§ÙÙŠØ©
        qafiya = self.qafiya_analyzer.analyze_qafiya(text, previous_lines)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø´Ø¹Ø± Ø§Ù„ØªÙØ¹ÙŠÙ„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©
        is_single_tafeela = self._check_single_tafeela(tafeelat)
        
        return ShatrAnalysis(
            original_text=text,
            arudi_text=arudi,
            binary_code=binary,
            tafeelat=tafeelat,
            meter_name=meter_match.get('meter_name'),
            meter_type=meter_match.get('meter_type'),
            meter_subtype=meter_match.get('meter_subtype', ''),
            confidence=confidence,
            is_valid=confidence >= 50,
            qafiya=qafiya,
            is_single_tafeela=is_single_tafeela
        )
    
    def _extract_tafeelat(self, binary: str) -> List[TafeelaResult]:
        detected = []
        i = 0
        sorted_taf = sorted(self.db.TAFEELAT.items(), key=lambda x: len(x[1]), reverse=True)
        
        while i < len(binary):
            matched = False
            for name, pattern in sorted_taf:
                if i + len(pattern) <= len(binary):
                    segment = binary[i:i+len(pattern)]
                    diff = sum(1 for a, b in zip(segment, pattern) if a != b)
                    if diff <= 1:
                        zahaf = None
                        if diff == 1:
                            zahaf = self._identify_zahaf(segment, pattern)
                        
                        detected.append(TafeelaResult(
                            name=name,
                            pattern=pattern,
                            actual=segment,
                            status='complete',
                            position=i,
                            zahaf=zahaf,
                            is_complete=(diff == 0)
                        ))
                        i += len(pattern)
                        matched = True
                        break
            if not matched:
                i += 1
        
        return detected
    
    def _identify_zahaf(self, variant: str, original: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø²Ø­Ø§Ù"""
        zahafat_map = {
            ('11010', '1100'): 'Ø®Ø¨Ù†',
            ('11010', '1110'): 'Ø·ÙŠ',
            ('1101010', '110100'): 'Ø®Ø¨Ù†',
            ('1101010', '110110'): 'Ø¥Ù‚Ø§Ù…Ø©',
            ('1011010', '101100'): 'Ø®Ø¨Ù†',
            ('1011010', '101110'): 'Ø·ÙŠ'
        }
        return zahafat_map.get((original, variant), 'Ø²Ø­Ø§Ù')
    
    def _match_meter(self, tafeelat: List[TafeelaResult]) -> Dict:
        if not tafeelat: 
            return {}
        
        detected_names = [t.name for t in tafeelat]
        best_match = {}
        max_score = 0
        
        for m_name, types in self.db.METERS.items():
            for m_type, expected in types.items():
                score = 0
                matched_count = 0
                
                for k, exp in enumerate(expected):
                    if k < len(detected_names):
                        if detected_names[k] == exp:
                            score += 1.0
                            matched_count += 1
                        elif self._are_related(detected_names[k], exp):
                            score += 0.7
                
                if expected:
                    final_score = score / len(expected)
                    coverage = matched_count / len(expected)
                    
                    if final_score > max_score and coverage >= 0.5:
                        max_score = final_score
                        meter_type_enum = self._get_meter_type_enum(m_type)
                        best_match = {
                            'meter_name': m_name,
                            'meter_type': meter_type_enum,
                            'meter_subtype': m_type,
                            'score': final_score
                        }
        
        return best_match
    
    def _get_meter_type_enum(self, type_str: str) -> MeterType:
        type_map = {
            'ØªØ§Ù…': MeterType.TAM,
            'Ù…Ø¬Ø²ÙˆØ¡': MeterType.MAJZOO,
            'Ù…Ø´Ø·ÙˆØ±': MeterType.MASHTOOR,
            'Ù…Ù†Ù‡ÙˆÙƒ': MeterType.MANHOOQ,
            'Ù…ØªÙØ§Ø¹Ù„Ø©': MeterType.MUTAFAILA
        }
        return type_map.get(type_str, MeterType.TAM)
    
    def _are_related(self, t1: str, t2: str) -> bool:
        if t1[:3] == t2[:3]:
            return True
        
        related_pairs = [
            ('ÙØ¹ÙˆÙ„Ù†', 'Ù…ÙØ§Ø¹ÙŠÙ„Ù†'), ('ÙØ§Ø¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'),
            ('Ù…Ø³ØªÙØ¹Ù„Ù†', 'ÙØ§Ø¹Ù„Ø§ØªÙ†'), ('Ù…ØªÙØ§Ø¹Ù„Ù†', 'Ù…ÙØ§Ø¹Ù„ØªÙ†'),
            ('Ù…ÙØ§Ø¹Ù„ØªÙ†', 'Ù…ÙØ§Ø¹Ù„Ù†'), ('ÙØ¹ÙˆÙ„Ù†', 'Ù…ÙØ§Ø¹Ù„ØªÙ†')
        ]
        
        return (t1, t2) in related_pairs or (t2, t1) in related_pairs
    
    def _calculate_confidence(self, tafeelat, match, binary):
        if not match or not tafeelat: 
            return 0.0
        
        base_confidence = min(100, (len(tafeelat) / (len(binary)/6)) * 100)
        meter_score = match.get('score', 0) * 100
        
        return (base_confidence + meter_score) / 2
    
    def _check_single_tafeela(self, tafeelat: List[TafeelaResult]) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø´Ø¹Ø± Ù…Ù† Ø§Ù„ØªÙØ¹ÙŠÙ„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©"""
        if not tafeelat:
            return False
        
        first_name = tafeelat[0].name
        return all(t.name == first_name for t in tafeelat)

def render_logo():
    st.markdown("""
    <div class="tam-logo-container">
        <div class="tam-musnad" dir="ltr">ğ©©ğ©±ğ©£</div>
        <div class="tam-english" dir="ltr">TAM PLATFORM</div>
        <div class="tam-arabic">ØªØ§Ù…</div>
        <div class="tam-separator"></div>
        <div class="tam-platform-name">Ù…Ù†ØµØ© ØªØ§Ù… Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©</div>
        <div class="farahidi-title"><span>ğŸ§ </span> Ø§Ù„ÙØ±Ø§Ù‡ÙŠØ¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…</div>
    </div>
    """, unsafe_allow_html=True)

def get_meter_badge_class(meter_type: MeterType) -> str:
    badge_map = {
        MeterType.TAM: 'badge-tam',
        MeterType.MAJZOO: 'badge-majzoo',
        MeterType.MASHTOOR: 'badge-mashtoor',
        MeterType.MANHOOQ: 'badge-manhooq',
        MeterType.MUTAFAILA: 'badge-mutafa'
    }
    return badge_map.get(meter_type, 'badge-tam')

def render_tafeela(tafeela: TafeelaResult, index: int):
    status_class = 'success' if tafeela.is_complete else 'warning' if tafeela.zahaf else 'error'
    status_symbol = "âœ“" if status_class == 'success' else "!" if status_class == 'warning' else "âœ—"
    
    zahaf_text = f'<div style="color: #ffa502; font-size: 0.9rem; margin-top: 5px;">Ø²Ø­Ø§Ù: {tafeela.zahaf}</div>' if tafeela.zahaf else ''
    
    st.markdown(f"""
    <div class="tafeela-card {status_class}">
        <div class="tafeela-status {status_class}">{status_symbol}</div>
        <div class="tafeela-name {status_class}">{tafeela.name}</div>
        <div class="tafeela-pattern">{tafeela.actual}</div>
        {zahaf_text}
    </div>
    """, unsafe_allow_html=True)

def render_qafiya(qafiya: QafiyaAnalysis):
    if not qafiya:
        return
    
    status_color = COLORS['success_green'] if qafiya.is_valid else COLORS['error_red']
    status_icon = "âœ…" if qafiya.is_valid else "âš ï¸"
    
    st.markdown(f"""
    <div class="qafiya-box">
        <div style="font-size: 1.5rem; font-weight: bold; color: {COLORS['purple']}; margin-bottom: 10px;">
            Ø§Ù„Ù‚Ø§ÙÙŠØ©: {qafiya.type.value}
        </div>
        <div style="font-size: 1.2rem; color: {COLORS['sandstone_cream']};">
            Ø§Ù„Ø±ÙˆÙŠ: <strong>{qafiya.rawwiy}</strong> ({qafiya.pattern})
        </div>
        <div style="color: {status_color}; margin-top: 10px;">
            {status_icon} {qafiya.details}
        </div>
    </div>
    """, unsafe_allow_html=True)

def render_result(res: ShatrAnalysis, shatr_num: int = 1):
    st.markdown(f"### Ø§Ù„Ø´Ø·Ø± {shatr_num}: {res.original_text}")
    
    # Ø¹Ø±Ø¶ Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø± ÙˆØ§Ù„Ù†ÙˆØ¹ (ØªØ§Ù…/Ù…Ø¬Ø²ÙˆØ¡/...)
    col1, col2, col3 = st.columns(3)
    
    with col1:
        meter = res.meter_name if res.meter_name else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        st.markdown(f"""
        <div class="result-card">
            <div>
                <div class="result-label">Ø§Ù„Ø¨Ø­Ø±</div>
                <div class="result-value">{meter}</div>
            </div>
        </div>""", unsafe_allow_html=True)
    
    with col2:
        if res.meter_type:
            badge_class = get_meter_badge_class(res.meter_type)
            type_name = res.meter_type.value
        else:
            badge_class = 'badge-tam'
            type_name = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
        
        st.markdown(f"""
        <div class="result-card">
            <div>
                <div class="result-label">Ø§Ù„Ù†ÙˆØ¹</div>
                <div class="result-value">
                    <span class="meter-type-badge {badge_class}">{type_name}</span>
                </div>
            </div>
        </div>""", unsafe_allow_html=True)
    
    with col3:
        color = "#4CAF50" if res.confidence > 80 else "#F44336" if res.confidence < 50 else "#ffa502"
        st.markdown(f"""
        <div class="result-card" style="border-right-color: {color}">
            <div>
                <div class="result-label">Ø§Ù„Ø«Ù‚Ø©</div>
                <div class="result-value" style="color:{color}">{int(res.confidence)}%</div>
            </div>
        </div>""", unsafe_allow_html=True)
    
    # ØªÙ†Ø¨ÙŠÙ‡ Ø´Ø¹Ø± Ø§Ù„ØªÙØ¹ÙŠÙ„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©
    if res.is_single_tafeela and res.tafeelat:
        st.markdown(f"""
        <div class="status-message warning">
            âš¡ <strong>Ø´Ø¹Ø± Ø§Ù„ØªÙØ¹ÙŠÙ„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©</strong><br>
            Ù‡Ø°Ø§ Ø§Ù„Ø´Ø·Ø± ÙŠØ³ØªØ®Ø¯Ù… ØªÙØ¹ÙŠÙ„Ø© ÙˆØ§Ø­Ø¯Ø© Ù…ØªÙƒØ±Ø±Ø©: <strong>{res.tafeelat[0].name}</strong>
        </div>
        """, unsafe_allow_html=True)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§ÙÙŠØ©
    if res.qafiya:
        render_qafiya(res.qafiya)
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ¹ÙŠÙ„Ø§Øª
    if res.tafeelat:
        st.markdown("#### ğŸ§© Ø§Ù„ØªÙØ¹ÙŠÙ„Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
        cols = st.columns(min(len(res.tafeelat), 4))
        for idx, tafeela in enumerate(res.tafeelat):
            with cols[idx % 4]:
                render_tafeela(tafeela, idx)
    
    # Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©
    with st.expander("ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©"):
        st.markdown("**Ø§Ù„Ù†Ù…Ø· Ø§Ù„ØµÙˆØªÙŠ (Binary):**")
        st.markdown(f'<div class="technical-box">{res.binary_code}</div>', unsafe_allow_html=True)
        st.markdown("**Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠ:**")
        st.markdown(f'<div class="technical-box">{res.arudi_text}</div>', unsafe_allow_html=True)

def render_footer():
    st.markdown("""
    <div class="tam-footer">
        Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù…Ø­ÙÙˆØ¸Ø© Â© 2026 Ù…Ù†ØµØ© ØªØ§Ù… Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ© | Ø§Ù„ÙØ±Ø§Ù‡ÙŠØ¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    </div>
    """, unsafe_allow_html=True)

def diacritics_tab():
    """Ù†Ø§ÙØ°Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØ§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù„ØºÙˆÙŠ"""
    st.markdown("### âœ¨ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù„ÙŠÙ‚ÙˆÙ… Ø§Ù„ÙØ±Ø§Ù‡ÙŠØ¯ÙŠ Ø¨ØªØ´ÙƒÙŠÙ„Ù‡ ÙˆØªØ¯Ù‚ÙŠÙ‚Ù‡:")
    
    raw_input = st.text_area(
        "Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù…",
        value=st.session_state.get('raw_text', ''),
        height=150,
        key="input_raw",
        placeholder="Ø§ÙƒØªØ¨ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§..."
    )
    
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        st.markdown('<div class="btn-gold">', unsafe_allow_html=True)
        if st.button("âœ¨ ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù†Øµ", use_container_width=True, key="btn_diacritics"):
            if raw_input:
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…Ø´ÙƒÙ‘Ù„ Ø§Ù„Ø°ÙƒÙŠ..."):
                    suggested_tashkeel = DiacriticsEngine.add_diacritics(raw_input)
                    st.session_state.final_text = suggested_tashkeel
                    st.session_state.raw_text = raw_input
            else:
                st.warning("Ø£Ø¯Ø®Ù„ Ù†ØµØ§Ù‹ Ø£ÙˆÙ„Ø§Ù‹.")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="btn-outline">', unsafe_allow_html=True)
        if st.button("ğŸ“‹ Ù…Ø«Ø§Ù„", use_container_width=True, key="btn_example_diac"):
            st.session_state.raw_text = "ÙˆØ­Ù„Ù Ø§Ù„Ù†ØµØ¨ ÙŠØ§ Ø§ÙŠØªÙˆÙ„ Ù‡Ù†Ø§\nØªÙˆØ´ÙŠ Ø§Ù„Ù„ÙŠÙ„ ÙˆØ§Ù„Ø§Ø­Ø²Ø§Ù† Ø¬Ù‡Ø±Ø§"
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col3:
        st.markdown('<div class="btn-danger">', unsafe_allow_html=True)
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­", use_container_width=True, key="btn_clear_diac"):
            st.session_state.raw_text = ""
            st.session_state.final_text = ""
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    if st.session_state.get('final_text'):
        st.markdown("### ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø© (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„ÙŠÙ‡Ø§):")
        
        final_input = st.text_area(
            "Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ø§Ù‡Ø²",
            value=st.session_state.final_text,
            height=150,
            key="editor_final"
        )
        
        if final_input != st.session_state.final_text:
            st.session_state.final_text = final_input
        
        st.markdown(f'<div class="diacritics-box">{st.session_state.final_text}</div>', unsafe_allow_html=True)
        st.code(st.session_state.final_text, language="text")
        st.info("ğŸ’¡ Ø§Ù†Ø³Ø® Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙˆØ§Ù†ØªÙ‚Ù„ Ù„Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©ØŒ Ø£Ùˆ Ø§Ø¶ØºØ· Ø²Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù‡Ù†Ø§Ùƒ Ù…Ø¨Ø§Ø´Ø±Ø©.")

def analysis_tab():
    """Ù†Ø§ÙØ°Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    st.markdown("### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ²Ù† Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    text_to_analyze = st.text_area(
        "",
        value=st.session_state.get('final_text', ''),
        height=150,
        key="analysis_input",
        placeholder="Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø´ÙƒÙ„ Ù‡Ù†Ø§..."
    )
    
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        st.markdown('<div class="btn-gold">', unsafe_allow_html=True)
        analyze = st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ØµÙŠØ¯Ø©", use_container_width=True, key="btn_analyze", type="primary")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="btn-outline">', unsafe_allow_html=True)
        if st.button("ğŸ“‹ Ù…Ø«Ø§Ù„", use_container_width=True, key="btn_example_anal"):
            st.session_state.final_text = "Ø³ÙÙŠÙØ³Ù’ØªÙØ¨Ù’Ù‚ÙÙŠ Ø§Ù„Ù‡ÙØªÙØ§ÙÙ Ø¥Ù„ÙÙŠÙ’ÙƒÙ Ø¯ÙÙ‡Ù’Ø±Ù‹Ø§\nÙÙØ´ÙÙ‚ÙÙ‘ Ø§Ù„Ø¯ÙÙ‘Ø±Ù’Ø¨Ù Ø¨ÙØ§Ù„Ø£ÙØ­Ù’Ø±ÙØ§Ø±Ù Ù†ÙØµÙ’Ø±Ù‹Ø§"
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col3:
        st.markdown('<div class="btn-danger">', unsafe_allow_html=True)
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­", use_container_width=True, key="btn_clear_anal"):
            st.session_state.final_text = ""
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    if analyze:
        if not text_to_analyze.strip():
            st.error("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ ÙˆØªØ´ÙƒÙŠÙ„Ù‡ ÙÙŠ Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø£ÙˆÙ„Ø§Ù‹!")
        else:
            analyzer = FarahidiAnalyzer()
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¨ÙŠØ§Øª
            lines = [s.strip() for s in re.split(r'[\n]', text_to_analyze) if s.strip()]
            previous_lines = []
            
            for idx, line in enumerate(lines):
                # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØª Ø¥Ù„Ù‰ Ø´Ø·Ø±ÙŠÙ† Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù…Ø© ØªÙ‚Ø³ÙŠÙ…
                shatrs = re.split(r'[ØŒ,]', line)
                
                for shatr_idx, shatr in enumerate(shatrs):
                    if shatr.strip():
                        res = analyzer.analyze(shatr.strip(), previous_lines)
                        render_result(res, idx + 1)
                        previous_lines.append(shatr.strip())
                        st.divider()

def main():
    render_logo()
    
    if 'raw_text' not in st.session_state:
        st.session_state.raw_text = ""
    if 'final_text' not in st.session_state:
        st.session_state.final_text = ""
    
    tab1, tab2 = st.tabs(["âœï¸ Ø§Ù„Ù…ÙØ´ÙƒÙ‘Ù„ Ø§Ù„Ø¢Ù„ÙŠ", "ğŸ” Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¹Ø±ÙˆØ¶ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"])
    
    with tab1:
        diacritics_tab()
    
    with tab2:
        analysis_tab()
    
    render_footer()

if __name__ == "__main__":
    main()
